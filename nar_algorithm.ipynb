{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwsuh/miniconda3/envs/nar/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/gwsuh/miniconda3/envs/nar/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/gwsuh/miniconda3/envs/nar/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/gwsuh/miniconda3/envs/nar/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/gwsuh/miniconda3/envs/nar/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/gwsuh/miniconda3/envs/nar/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/gwsuh/miniconda3/envs/nar/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/gwsuh/miniconda3/envs/nar/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/gwsuh/miniconda3/envs/nar/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/gwsuh/miniconda3/envs/nar/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/gwsuh/miniconda3/envs/nar/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/gwsuh/miniconda3/envs/nar/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# for SPOT-RNA\n",
    "from SPOT_RNA.utils.utils import create_tfr_files\n",
    "from SPOT_RNA.utils.FastaMLtoSL import FastaMLtoSL\n",
    "import tensorflow as tf\n",
    "\n",
    "# for E2Efold & REDfold\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import sys\n",
    "import collections\n",
    "# import _pickle as cPickle\n",
    "import dill as cPickle\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from Bio import SeqIO\n",
    "from itertools import product\n",
    "\n",
    "from E2Efold.model.models import ContactAttention_simple_fix_PE, Lag_PP_mixed, RNA_SS_e2e\n",
    "from E2Efold.utils.utils import *\n",
    "from E2Efold.data_generator.data_generator import RNASSDataGenerator as RNASSDataGeneratorE2E, Dataset\n",
    "from E2Efold.utils.postprocess import  postprocess_proposed as postprocess_proposed_e2e\n",
    "\n",
    "from REDfold.utils.utils import *\n",
    "from REDfold.data_generator.data_generator import RNASSDataGenerator as RNASSDataGeneratorRED\n",
    "from REDfold.data_generator.data_generator import Dataset_Cut_concat_new_canonicle as Dataset_FCN\n",
    "from REDfold.model.models import FCDenseNet\n",
    "from REDfold.utils.postprocess import postprocess_proposed as postprocess_proposed_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E2E_pickle_make(seq_name, sequence, output_path):\n",
    "  RNA_SS_data = collections.namedtuple('RNA_SS_data', 'seq ss_label length name pairs')\n",
    "  label_dict = {\n",
    "    '.': np.array([1,0,0]), \n",
    "    '(': np.array([0,1,0]), \n",
    "    ')': np.array([0,0,1])\n",
    "  }\n",
    "  seq_dict = {\n",
    "      'A':np.array([1,0,0,0]),\n",
    "      'U':np.array([0,1,0,0]),\n",
    "      'C':np.array([0,0,1,0]),\n",
    "      'G':np.array([0,0,0,1]),\n",
    "      'N':np.array([0,0,0,0])\n",
    "  }\n",
    "\n",
    "  def seq_encoding(string):\n",
    "      str_list = list(string)\n",
    "      encoding = list(map(lambda x: seq_dict[x], str_list))\n",
    "      # need to stack\n",
    "      return np.stack(encoding, axis=0)\n",
    "\n",
    "  def stru_encoding(string):\n",
    "      str_list = list(string)\n",
    "      encoding = list(map(lambda x: label_dict[x], str_list))\n",
    "      # need to stack\n",
    "      return np.stack(encoding, axis=0)\n",
    "\n",
    "  def padding(data_array, maxlen):\n",
    "      a, b = data_array.shape\n",
    "      return np.pad(data_array, ((0,maxlen-a),(0,0)), 'constant')\n",
    "  \n",
    "  length_limit = 600\n",
    "  \n",
    "  structure_list = list()\n",
    "  seq_list = list()\n",
    "  \n",
    "  seq_len_list = list()\n",
    "  file_list = list()\n",
    "  pairs_list = list()\n",
    "  \n",
    "  file_list.append(seq_name)\n",
    "  seq_len_list.append(len(sequence))\n",
    "  pairs_list.append([])\n",
    "  \n",
    "  structure_list.append('.'*len(sequence))\n",
    "  seq_list.append(sequence.upper())\n",
    "  \n",
    "  seq_encoding_list = list(map(seq_encoding, seq_list))\n",
    "  stru_encoding_list = list(map(stru_encoding, structure_list))\n",
    "  \n",
    "  seq_encoding_list_padded = list(map(lambda x: padding(x, length_limit), \n",
    "    seq_encoding_list))\n",
    "  stru_encoding_list_padded = list(map(lambda x: padding(x, length_limit), \n",
    "    stru_encoding_list))\n",
    "  \n",
    "  \n",
    "  RNA_SS_data_list = list()\n",
    "  for i in range(1):\n",
    "      RNA_SS_data_list.append(RNA_SS_data(seq=seq_encoding_list_padded[i],\n",
    "          ss_label=stru_encoding_list_padded[i], \n",
    "          length=seq_len_list[i], name=file_list[i], pairs=pairs_list[i]))\n",
    "      \n",
    "  with open(os.path.join(output_path, seq_name+'.pickle') , 'wb') as f:\n",
    "    cPickle.dump(RNA_SS_data_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RED_pickle_make(seq_name, sequence, output_path):\n",
    "  RNA_SS_data = collections.namedtuple('RNA_SS_data','name length seq_hot data_pair data_seq1 data_seq2')\n",
    "  \n",
    "  BASE1 = 'AUCG'\n",
    "  pair_set= {'AU','UA','CG','GC','GU','UG'}\n",
    "\n",
    "  global npBASE1\n",
    "  global dcBASE2\n",
    "  \n",
    "  npBASE1= np.array([b1 for b1 in BASE1])\n",
    "  npBASE2= np.array([\"\".join(b2) for b2 in product(npBASE1,npBASE1)])\n",
    "  dcBASE2= {}\n",
    "  for [a,b] in enumerate(npBASE2):\n",
    "    dcBASE2[b]= a\n",
    "\n",
    "  def one_hot(seq1):\n",
    "      RNA_seq= seq1\n",
    "\n",
    "      feat= np.concatenate([[(npBASE1 == base.upper()).astype(int)] \n",
    "            if str(base).upper() in BASE1 else np.array([[0] * len(BASE1)]) for base in RNA_seq])\n",
    "\n",
    "      return feat\n",
    "\n",
    "  def one_hot_2m(seq1):\n",
    "      L1= len(seq1)\n",
    "      feat= np.zeros((L1,16))\n",
    "      for i in range(0,L1-1):\n",
    "        Id1= str(seq1[i:i+2]).upper()\n",
    "        if Id1 in dcBASE2:\n",
    "          feat[i,dcBASE2[Id1]]= 1\n",
    "      #Circle Back 2mer\n",
    "      Id1= str(seq1[-1]+seq1[0]).upper()\n",
    "      feat[L1-1,dcBASE2[Id1]]= 1\n",
    "\n",
    "      return feat\n",
    "\n",
    "  def get_cut_len(data_len,set_len):\n",
    "      L= data_len\n",
    "      if L<= set_len:\n",
    "          L= set_len\n",
    "      else:\n",
    "          L= (((L - 1) // 16) + 1) * 16\n",
    "      return L\n",
    "\n",
    "  def pair2map(pairs, seq_len):\n",
    "    pmap= np.zeros([seq_len, seq_len])\n",
    "    for pair in pairs:\n",
    "      pmap[pair[0], pair[1]] = 1\n",
    "    return pmap\n",
    "  \n",
    "  all_files_list = []\n",
    "  \n",
    "  one_hot_matrix= one_hot(sequence.upper())\n",
    "  one_hot_mat2= one_hot_2m(sequence.upper())\n",
    "  \n",
    "  pair_dict_all_list = []\n",
    "  \n",
    "  seq_name = seq_name\n",
    "  seq_len = len(sequence)\n",
    "  \n",
    "  # pair_dict_all = dict()\n",
    "  \n",
    "  # ss_label = np.zeros((seq_len,3),dtype=int)\n",
    "  \n",
    "  L= get_cut_len(seq_len,80)\n",
    "  \n",
    "  ##-Trans seq to seq_length\n",
    "  one_hot_matrix_LM= np.zeros((L,4))\n",
    "  one_hot_matrix_LM[:seq_len,]= one_hot_matrix\n",
    "  # ss_label_L= np.zeros((L,3),dtype=int)\n",
    "\n",
    "  one_hot_mat2_LM= np.zeros((L,16))\n",
    "  one_hot_mat2_LM[:seq_len,]= one_hot_mat2\n",
    "  \n",
    "  data_seq1= one_hot_matrix_LM\n",
    "  data_seq2= one_hot_mat2_LM\n",
    "\n",
    "  ##-Seq_onehot\n",
    "  seq_hot= one_hot_matrix_LM[:L,:]\n",
    "  data_pair= pair2map(pair_dict_all_list,L)\n",
    "  \n",
    "  sample_tmp= RNA_SS_data(name=seq_name, length=seq_len, seq_hot=seq_hot, data_pair=data_pair, data_seq1= data_seq1, data_seq2=data_seq2)      \n",
    "  all_files_list.append(sample_tmp)\n",
    "  \n",
    "  with open(os.path.join(output_path, seq_name+'.pickle'), 'wb') as f:\n",
    "    cPickle.dump(all_files_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SPOT_fasta_make(seq_name, sequence, output_path):\n",
    "  lines = ['>'+seq_name+'\\n', sequence.upper()+'\\n']\n",
    "  with open(os.path.join(output_path, seq_name+'.fasta'), 'w') as f:\n",
    "    f.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '/media/ksj/nar_web_rna/test'\n",
    "sequence = 'AUGUCGAUCGACUAGAUGCUACCCC'\n",
    "seq_name = 'test'\n",
    "\n",
    "E2E_pickle_make(seq_name+'_e2e',sequence,output_path)\n",
    "RED_pickle_make(seq_name+'_red',sequence,output_path)\n",
    "SPOT_fasta_make(seq_name,sequence,output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exac_E2E(pickle_path, device_num = 0):\n",
    "  # nc seed 2 epoch 20 s 4\n",
    "  model_path = '/media/ksj/nar_web_rna/E2Efold/model/e2efold_model_new.pt'\n",
    "  d = 10\n",
    "  BATCH_SIZE = 1\n",
    "  pp_steps = 20\n",
    "  k = 1\n",
    "  s = 4\n",
    "  \n",
    "  # 여기 개수에 따라 바꿔줘야 함\n",
    "  os.environ[\"CUDA_VISIBLE_DEVICES\"] = generate_visible_device(2)\n",
    "\n",
    "  device = torch.device('cuda:{}'.format(device_num))\n",
    "  \n",
    "  RNA_SS_data = collections.namedtuple('RNA_SS_data', 'seq ss_label length name pairs')\n",
    "  \n",
    "  test_data = RNASSDataGeneratorE2E(pickle_path)\n",
    "\n",
    "  seq_len = test_data.data_y.shape[-2]\n",
    "\n",
    "  params = {'batch_size': BATCH_SIZE,\n",
    "            'shuffle': True,\n",
    "            'num_workers': 6,\n",
    "            'drop_last': True}\n",
    "  \n",
    "  test_set = Dataset(test_data)\n",
    "  test_generator = data.DataLoader(test_set, **params)\n",
    "\n",
    "  contact_net = ContactAttention_simple_fix_PE(d=d, L=seq_len).to(device)\n",
    "  lag_pp_net = Lag_PP_mixed(pp_steps, k, device=device_num).to(device)\n",
    "  rna_ss_e2e = RNA_SS_e2e(contact_net.to(device), lag_pp_net.to(device)).to(device)\n",
    "  rna_ss_e2e.load_state_dict(torch.load(model_path, map_location = device))\n",
    "  rna_ss_e2e.to(device)\n",
    "\n",
    "  contact_net = rna_ss_e2e.model_att\n",
    "  lag_pp_net = rna_ss_e2e.model_pp\n",
    "\n",
    "  contact_net.eval()\n",
    "  lag_pp_net.eval()\n",
    "  rna_ss_e2e.eval()\n",
    "  \n",
    "  for index, [contacts, seq_embeddings, matrix_reps, seq_lens, data_name] in enumerate(tqdm(test_generator, desc='test data loading...', ascii=True)):\n",
    "    \n",
    "    contacts_batch = torch.Tensor(contacts.float()).to(device)\n",
    "    seq_embedding_batch = torch.Tensor(seq_embeddings.float()).to(device)\n",
    "    # matrix_reps_batch = torch.unsqueeze(\n",
    "    #     torch.Tensor(matrix_reps.float()).to(device), -1)\n",
    "\n",
    "    state_pad = torch.zeros(contacts.shape).to(device)\n",
    "\n",
    "    PE_batch = get_pe(seq_lens, contacts.shape[-1]).float().to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "      pred_contacts, a_pred_list = rna_ss_e2e(PE_batch, seq_embedding_batch, state_pad)\n",
    "\n",
    "      u_no_train_2 = postprocess_proposed_e2e(pred_contacts[:,:seq_lens, :seq_lens], seq_embedding_batch[:,:seq_lens,:seq_lens],s=s, process_device=device_num)\n",
    "      \n",
    "      return(u_no_train_2[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exac_RED(pickle_path, device_num = 0):\n",
    "  # nc seed 2 epoch 124 s 0\n",
    "  model_path = '/media/ksj/nar_web_rna/REDfold/model/redfold_model_new.pt'\n",
    "\n",
    "  # 나중에 바꾸기\n",
    "  num_of_device = 2\n",
    "  use_device_num = device_num\n",
    "  batch_n = 1\n",
    "  set_gamma = 0\n",
    "  set_rho= set_gamma+0.1\n",
    "  set_L1= 1\n",
    "  \n",
    "  RNA_SS_data = collections.namedtuple('RNA_SS_data','name length seq_hot data_pair data_seq1 data_seq2')\n",
    "  \n",
    "  os.environ[\"CUDA_VISIBLE_DEVICES\"] = generate_visible_device(num_of_device)\n",
    "\n",
    "  device = torch.device('cuda:{}'.format(use_device_num))\n",
    "\n",
    "  Use_gpu= torch.cuda.is_available()\n",
    "\n",
    "  print('test data loading...')\n",
    "\n",
    "  test_data= RNASSDataGeneratorRED(pickle_path,720)\n",
    "  test_len= len(test_data)\n",
    "  test_set= Dataset_FCN(test_data)\n",
    "\n",
    "  dataloader_test= DataLoader(dataset=test_set, batch_size=batch_n, shuffle=1, num_workers=12)\n",
    "\n",
    "  #- Network\n",
    "  model= FCDenseNet(in_channels=146,out_channels=1,\n",
    "                  initial_num_features=16,\n",
    "                  dropout=0,\n",
    "\n",
    "                  down_dense_growth_rates=(4,8,16,32),\n",
    "                  down_dense_bottleneck_ratios=None,\n",
    "                  down_dense_num_layers=(4,4,4,4),\n",
    "                  down_transition_compression_factors=1.0,\n",
    "\n",
    "                  middle_dense_growth_rate=32,\n",
    "                  middle_dense_bottleneck=None,\n",
    "                  middle_dense_num_layers=8,\n",
    "\n",
    "                  up_dense_growth_rates=(64,32,16,8),\n",
    "                  up_dense_bottleneck_ratios=None,\n",
    "                  up_dense_num_layers=(4,4,4,4))\n",
    "\n",
    "  optimizer= torch.optim.Adam(model.parameters())\n",
    "\n",
    "  # Model on GPU\n",
    "  if Use_gpu:\n",
    "      model= model.to(device)\n",
    "\n",
    "  mod_state= torch.load(model_path, map_location=device)\n",
    "  model.load_state_dict(mod_state)\n",
    "\n",
    "  model.eval()\n",
    "  \n",
    "  for index, [x1, y1, L1, seq_hot,seq_name] in enumerate(tqdm(dataloader_test, desc='testing...', ascii=True)): \n",
    "    # Data on GPU\n",
    "    if Use_gpu:\n",
    "        x1= x1.to(device).type(torch.cuda.FloatTensor)\n",
    "        y1= y1.to(device).type(torch.cuda.FloatTensor)\n",
    "\n",
    "    [x1, y1]= Variable(x1), Variable(y1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_pred= model(x1)\n",
    "    \n",
    "    # post-processing without learning train\n",
    "    seq_hot=seq_hot.to(device)\n",
    "    y_mask_proposed = postprocess_proposed_red(y_pred, seq_hot, set_gamma, use_device_num)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    print(y_mask_proposed[0][:L1,:L1].shape)\n",
    "    \n",
    "    return(y_mask_proposed[0][:L1,:L1].cpu().numpy())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exac_SPOT(fasta_path, device_num):\n",
    "  # tfr_path = os.path.dirname(fasta_path)\n",
    "  \n",
    "  os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "  tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "  FastaMLtoSL(fasta_path)\n",
    "\n",
    "  base_path = os.path.dirname(fasta_path)\n",
    "  input_file = os.path.basename(fasta_path)\n",
    "  \n",
    "  # if not os.path.exists(os.path.join(base_path, '/input_tfr_files')):\n",
    "  #   os.makedirs(os.path.join(base_path, '/input_tfr_files'))\n",
    "\n",
    "  create_tfr_files(fasta_path, base_path, input_file)\n",
    "  \n",
    "  with open(fasta_path) as file:\n",
    "    input_data = [line.strip() for line in file.read().splitlines() if line.strip()]\n",
    "\n",
    "  count = int(len(input_data)/2)\n",
    "\n",
    "  ids = [input_data[2*i].replace(\">\", \"\") for i in range(count)]\n",
    "  sequences = {}\n",
    "  \n",
    "  for i,I in enumerate(ids):\n",
    "    sequences[I] = input_data[2*i+1].replace(\" \", \"\").upper().replace(\"T\", \"U\")\n",
    "\n",
    "  os.environ[\"CUDA_VISIBLE_DEVICES\"]= str(device_num)\n",
    "  #os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "  NUM_MODELS = 5\n",
    "\n",
    "  test_loc = [os.path.join(base_path, 'input_tfr_files', input_file+'.tfrecords')]\n",
    "\n",
    "  outputs = {}\n",
    "  mask = {}\n",
    "  def sigmoid(x):\n",
    "      return 1/(1+np.exp(-np.array(x, dtype=np.float128)))\n",
    "  \n",
    "  for MODEL in range(NUM_MODELS):\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.allow_soft_placement=True\n",
    "    config.log_device_placement=False\n",
    "    config.gpu_options.allow_growth = True\n",
    "\n",
    "    print('\\nPredicting for SPOT-RNA model '+str(MODEL))\n",
    "    with tf.compat.v1.Session(config=config) as sess:\n",
    "        saver = tf.compat.v1.train.import_meta_graph(os.path.join('/media/ksj/nar_web_rna/SPOT_RNA/SPOT-RNA-models', 'model' + str(MODEL) + '.meta'))\n",
    "        saver.restore(sess,os.path.join('/media/ksj/nar_web_rna/SPOT_RNA/SPOT-RNA-models', 'model' + str(MODEL)))\n",
    "        graph = tf.compat.v1.get_default_graph()\n",
    "        init_test =  graph.get_operation_by_name('make_initializer_2')\n",
    "        tmp_out = graph.get_tensor_by_name('output_FC/fully_connected/BiasAdd:0')\n",
    "        name_tensor = graph.get_tensor_by_name('tensors_2/component_0:0')\n",
    "        RNA_name = graph.get_tensor_by_name('IteratorGetNext:0')\n",
    "        label_mask = graph.get_tensor_by_name('IteratorGetNext:4')\n",
    "        sess.run(init_test,feed_dict={name_tensor:test_loc})\n",
    "        \n",
    "        pbar = tqdm(total = count)\n",
    "        while True:\n",
    "            try:        \n",
    "                out = sess.run([tmp_out,RNA_name,label_mask],feed_dict={'dropout:0':1})\n",
    "                out[1] = out[1].decode()\n",
    "                mask[out[1]] = out[2]\n",
    "                \n",
    "                if MODEL == 0:\n",
    "                    outputs[out[1]] = [sigmoid(out[0])]\n",
    "                else:\n",
    "                    outputs[out[1]].append(sigmoid(out[0]))\n",
    "                #print('RNA name: %s'%(out[1]))\n",
    "                pbar.update(1)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "        pbar.close()\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "  RNA_ids = [i for i in list(outputs.keys())]\n",
    "  ensemble_outputs = {} \n",
    "  \n",
    "  def output_mask(seq, NC=True):\n",
    "      if NC:\n",
    "          include_pairs = ['AU', 'UA', 'GC', 'CG', 'GU', 'UG', 'CC', 'GG', 'AG', 'CA', 'AC', 'UU', 'AA', 'CU', 'GA', 'UC']\n",
    "      else:\n",
    "          include_pairs = ['AU', 'UA', 'GC', 'CG', 'GU', 'UG']\n",
    "      mask = np.zeros((len(seq), len(seq)))\n",
    "      for i, I in enumerate(seq):\n",
    "          for j, J in enumerate(seq):\n",
    "              if str(I) + str(J) in include_pairs:\n",
    "                  mask[i, j] = 1\n",
    "      return mask\n",
    "  \n",
    "  for i in RNA_ids:\n",
    "    ensemble_outputs[i] = np.mean(outputs[i],0)\n",
    "    \n",
    "    # print('\\n\\n\\n\\n\\n shape: {} \\n\\n\\n\\n\\n'.format(np.array(ensemble_outputs[i]).shape))\n",
    "    \n",
    "    ensemble_outputs_post = ensemble_outputs[i]\n",
    "    label_mask = mask[i]\n",
    "    seq = sequences[i]\n",
    "    name = i\n",
    "    Threshold = 0.335\n",
    "    test_output = ensemble_outputs_post\n",
    "    mask_post = output_mask(seq)\n",
    "    inds = np.where(label_mask == 1)\n",
    "    y_pred = np.zeros(label_mask.shape)\n",
    "    \n",
    "    for i in range(test_output.shape[0]):\n",
    "        y_pred[inds[0][i], inds[1][i]] = test_output[i]\n",
    "    y_pred = np.multiply(y_pred, mask_post)\n",
    "    \n",
    "    return(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Opening FASTA file...\n",
      ">> Converting FASTA file from multiline to single line and writing to file.\n",
      ">> Done!\n",
      "\n",
      "Preparing tfr records file for SPOT-RNA:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 115.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting for SPOT-RNA model 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "File /media/ksj/nar_web_rna/test/SPOT-RNA-models/model0.meta does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-8f2f29c77c16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexac_SPOT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/media/ksj/nar_web_rna/test/test.fasta'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-55-b9f105b9f54f>\u001b[0m in \u001b[0;36mexac_SPOT\u001b[0;34m(fasta_path, device_num)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nPredicting for SPOT-RNA model '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_meta_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SPOT-RNA-models'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.meta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SPOT-RNA-models'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nar/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mimport_meta_graph\u001b[0;34m(meta_graph_or_file, clear_devices, import_scope, **kwargs)\u001b[0m\n\u001b[1;32m   1447\u001b[0m   return _import_meta_graph_with_return_elements(meta_graph_or_file,\n\u001b[1;32m   1448\u001b[0m                                                  \u001b[0mclear_devices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m                                                  **kwargs)[0]\n\u001b[0m\u001b[1;32m   1450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nar/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_import_meta_graph_with_return_elements\u001b[0;34m(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs)\u001b[0m\n\u001b[1;32m   1461\u001b[0m                        \"execution is enabled.\")\n\u001b[1;32m   1462\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_graph_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_graph_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMetaGraphDef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1463\u001b[0;31m     \u001b[0mmeta_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_meta_graph_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_graph_or_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1464\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m     \u001b[0mmeta_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_graph_or_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nar/lib/python3.6/site-packages/tensorflow/python/framework/meta_graph.py\u001b[0m in \u001b[0;36mread_meta_graph_file\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    682\u001b[0m   \u001b[0mmeta_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_graph_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMetaGraphDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File %s does not exist.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m   \u001b[0;31m# First try to read it as a binary file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m   \u001b[0mfile_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: File /media/ksj/nar_web_rna/test/SPOT-RNA-models/model0.meta does not exist."
     ]
    }
   ],
   "source": [
    "a = exac_SPOT('/media/ksj/nar_web_rna/test/test.fasta',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwsuh/miniconda3/envs/nar/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/gwsuh/miniconda3/envs/nar/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/gwsuh/miniconda3/envs/nar/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/gwsuh/miniconda3/envs/nar/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/gwsuh/miniconda3/envs/nar/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/gwsuh/miniconda3/envs/nar/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/gwsuh/miniconda3/envs/nar/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/gwsuh/miniconda3/envs/nar/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/gwsuh/miniconda3/envs/nar/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/gwsuh/miniconda3/envs/nar/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/gwsuh/miniconda3/envs/nar/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/gwsuh/miniconda3/envs/nar/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from nar_algorithm2npy import al2npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test data loading...:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(al2npy(algorithm='e2efold',uuid='TETETEST',seq_name='testtest',sequence='AUCGAUCGAUGCAC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
